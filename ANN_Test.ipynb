{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   time  channel1  channel2  channel3  channel4  channel5  channel6  channel7   \n",
      "0     1   0.00001  -0.00002  -0.00001  -0.00003   0.00000  -0.00001   0.00000  \\\n",
      "1     5   0.00001  -0.00002  -0.00001  -0.00003   0.00000  -0.00001   0.00000   \n",
      "2     6  -0.00001   0.00001   0.00002   0.00000   0.00001  -0.00002  -0.00001   \n",
      "3     7  -0.00001   0.00001   0.00002   0.00000   0.00001  -0.00002  -0.00001   \n",
      "4     8  -0.00001   0.00001   0.00002   0.00000   0.00001  -0.00002  -0.00001   \n",
      "\n",
      "   channel8  class  label  \n",
      "0  -0.00001      0      1  \n",
      "1  -0.00001      0      1  \n",
      "2   0.00001      0      1  \n",
      "3   0.00001      0      1  \n",
      "4   0.00001      0      1  \n",
      "(4237907, 11)\n"
     ]
    }
   ],
   "source": [
    "dataset=pd.read_csv(\"EMG-data.csv\") \n",
    "print(dataset.head())\n",
    "print(dataset.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "empty values: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nempty values:\",dataset.isnull().any().sum()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7]\n",
      "Value Count :\n",
      " class\n",
      "0    2725157\n",
      "6     253009\n",
      "5     251733\n",
      "4     251570\n",
      "1     250055\n",
      "3     249494\n",
      "2     243193\n",
      "7      13696\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "dataset=dataset.drop(columns=[\"time\"])\n",
    "Class = dataset[\"class\"]\n",
    "print(Class.unique())\n",
    "print(\"Value Count :\\n\", dataset[\"class\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "##drop gesture 0 because it offers no information due to its unmarked nature\n",
    "index_numbers_1=dataset[dataset[\"class\"]==0].index \n",
    "dataset.drop(index_numbers_1,inplace=True)\n",
    "##drop gesture 7 because it offers no information due to it being performed \n",
    "##by just two out of 36 patients \n",
    "index_numbers_2=dataset[dataset[\"class\"]==7].index\n",
    "dataset.drop(index_numbers_2,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=dataset.groupby(['label','class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "##functions for extracting sEMG features\n",
    "def rms(data): ##root mean square\n",
    "      return  np.sqrt(np.mean(data**2,axis=0))  \n",
    "\n",
    "def SSI(data): ##Simple Square Integral\n",
    "    return np.sum(data**2,axis=0)\n",
    "\n",
    "def abs_diffs_signal(data): ##absolute differential signal\n",
    "    return np.sum(np.abs(np.diff(data,axis=0)),axis=0)\n",
    "\n",
    "##function for returning an estimator class name \n",
    "def print_estimator_name(estimator):\n",
    "    return estimator.__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "##tabulating the aggregated sEMG features\n",
    "dataset=dataset.agg(['min','max',rms,SSI,abs_diffs_signal,np.ptp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>class</th>\n",
       "      <th colspan=\"6\" halign=\"left\">channel1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">channel2</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"4\" halign=\"left\">channel7</th>\n",
       "      <th colspan=\"6\" halign=\"left\">channel8</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>rms</th>\n",
       "      <th>SSI</th>\n",
       "      <th>abs_diffs_signal</th>\n",
       "      <th>ptp</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>...</th>\n",
       "      <th>rms</th>\n",
       "      <th>SSI</th>\n",
       "      <th>abs_diffs_signal</th>\n",
       "      <th>ptp</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>rms</th>\n",
       "      <th>SSI</th>\n",
       "      <th>abs_diffs_signal</th>\n",
       "      <th>ptp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.00005</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.01070</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>-0.00010</td>\n",
       "      <td>0.00007</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.00870</td>\n",
       "      <td>0.00006</td>\n",
       "      <td>-0.00005</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.00921</td>\n",
       "      <td>0.00007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.00111</td>\n",
       "      <td>0.00095</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>0.16819</td>\n",
       "      <td>0.00206</td>\n",
       "      <td>-0.00047</td>\n",
       "      <td>0.00041</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000318</td>\n",
       "      <td>0.16251</td>\n",
       "      <td>0.00153</td>\n",
       "      <td>-0.00070</td>\n",
       "      <td>0.00054</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.11696</td>\n",
       "      <td>0.00124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.00087</td>\n",
       "      <td>0.00112</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>0.14544</td>\n",
       "      <td>0.00199</td>\n",
       "      <td>-0.00113</td>\n",
       "      <td>0.00127</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.05866</td>\n",
       "      <td>0.00063</td>\n",
       "      <td>-0.00073</td>\n",
       "      <td>0.00051</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>0.11869</td>\n",
       "      <td>0.00124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.00020</td>\n",
       "      <td>0.00016</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.03609</td>\n",
       "      <td>0.00036</td>\n",
       "      <td>-0.00038</td>\n",
       "      <td>0.00024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.07517</td>\n",
       "      <td>0.00090</td>\n",
       "      <td>-0.00032</td>\n",
       "      <td>0.00026</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.04984</td>\n",
       "      <td>0.00058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.00031</td>\n",
       "      <td>0.00061</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.04939</td>\n",
       "      <td>0.00092</td>\n",
       "      <td>-0.00066</td>\n",
       "      <td>0.00035</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.06768</td>\n",
       "      <td>0.00055</td>\n",
       "      <td>-0.00030</td>\n",
       "      <td>0.00045</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.04606</td>\n",
       "      <td>0.00075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  label class channel1                                                          \n",
       "                   min      max       rms       SSI abs_diffs_signal      ptp   \n",
       "0     1     1 -0.00005  0.00004  0.000017  0.000002          0.01070  0.00009  \\\n",
       "1     1     2 -0.00111  0.00095  0.000210  0.000301          0.16819  0.00206   \n",
       "2     1     3 -0.00087  0.00112  0.000188  0.000260          0.14544  0.00199   \n",
       "3     1     4 -0.00020  0.00016  0.000056  0.000022          0.03609  0.00036   \n",
       "4     1     5 -0.00031  0.00061  0.000066  0.000030          0.04939  0.00092   \n",
       "\n",
       "  channel2           ...  channel7                                       \n",
       "       min      max  ...       rms       SSI abs_diffs_signal      ptp   \n",
       "0 -0.00010  0.00007  ...  0.000013  0.000001          0.00870  0.00006  \\\n",
       "1 -0.00047  0.00041  ...  0.000216  0.000318          0.16251  0.00153   \n",
       "2 -0.00113  0.00127  ...  0.000078  0.000044          0.05866  0.00063   \n",
       "3 -0.00038  0.00024  ...  0.000118  0.000095          0.07517  0.00090   \n",
       "4 -0.00066  0.00035  ...  0.000084  0.000049          0.06768  0.00055   \n",
       "\n",
       "  channel8                                                         \n",
       "       min      max       rms       SSI abs_diffs_signal      ptp  \n",
       "0 -0.00005  0.00002  0.000014  0.000001          0.00921  0.00007  \n",
       "1 -0.00070  0.00054  0.000150  0.000153          0.11696  0.00124  \n",
       "2 -0.00073  0.00051  0.000161  0.000190          0.11869  0.00124  \n",
       "3 -0.00032  0.00026  0.000083  0.000047          0.04984  0.00058  \n",
       "4 -0.00030  0.00045  0.000060  0.000025          0.04606  0.00075  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset=dataset.reset_index()\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp2=dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators=[]\n",
    "accuracy=[]\n",
    "f1_macro=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moham\\AppData\\Local\\Temp\\ipykernel_3520\\1506687212.py:1: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  features=dataset.drop(columns=[\"label\",\"class\"])\n"
     ]
    }
   ],
   "source": [
    "features=dataset.drop(columns=[\"label\",\"class\"])\n",
    "labels=dataset[\"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Training and testing set splitting\n",
    "X_train, X_test,y_train,y_test= train_test_split(features,labels,test_size=0.30, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data normalization\n",
    "mean = X_train.mean(axis=0)\n",
    "std = X_train.std(axis=0)\n",
    "X_train -= mean\n",
    "X_train /= std\n",
    "X_test -= mean\n",
    "X_test /= std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape (151, 48)\n",
      "x_test shape (65, 48)\n",
      "y_train shape (151,)\n",
      "y_test shape (65,)\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train shape\",X_train.shape)\n",
    "print(\"x_test shape\",X_test.shape)\n",
    "print(\"y_train shape\",y_train.shape)\n",
    "print(\"y_test shape\",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train -1\n",
    "y_test = y_test  - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingtarget = y_train\n",
    "testtarget  = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14     2\n",
       "138    0\n",
       "122    2\n",
       "56     2\n",
       "185    5\n",
       "      ..\n",
       "203    5\n",
       "137    5\n",
       "72     0\n",
       "140    2\n",
       "37     1\n",
       "Name: class, Length: 151, dtype: int64"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingtarget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "# Convert labels to one-hot encoded format\n",
    "trainLabels  = to_categorical(trainingtarget)\n",
    "testLabels   = to_categorical(testtarget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65, 6)"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testLabels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, Sequential, optimizers, Input, Model\n",
    "\n",
    "model = Sequential([\n",
    "    layers.Dense(1024, input_shape=(48,), activation='relu'),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(0.2),  # Adding dropout with a rate of 0.2\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.2),  # Adding dropout with a rate of 0.2\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(16, activation='relu'),\n",
    "    layers.Dense(6, activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_167 (Dense)           (None, 1024)              50176     \n",
      "                                                                 \n",
      " dense_168 (Dense)           (None, 512)               524800    \n",
      "                                                                 \n",
      " dense_169 (Dense)           (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_46 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_170 (Dense)           (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_171 (Dense)           (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_47 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_172 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_173 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_174 (Dense)           (None, 6)                 102       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 750,166\n",
      "Trainable params: 750,166\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor=\"loss\",patience=3)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(151, 48)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1.7922 - accuracy: 0.2000 - val_loss: 1.7510 - val_accuracy: 0.2391\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.7209 - accuracy: 0.2952 - val_loss: 1.6775 - val_accuracy: 0.1957\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.6172 - accuracy: 0.3429 - val_loss: 1.5829 - val_accuracy: 0.2174\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.5246 - accuracy: 0.3143 - val_loss: 1.4787 - val_accuracy: 0.3913\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4046 - accuracy: 0.4857 - val_loss: 1.4145 - val_accuracy: 0.5435\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.2770 - accuracy: 0.4857 - val_loss: 1.3551 - val_accuracy: 0.5435\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.1865 - accuracy: 0.6762 - val_loss: 1.2949 - val_accuracy: 0.6087\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.0525 - accuracy: 0.6762 - val_loss: 1.2533 - val_accuracy: 0.6739\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.9823 - accuracy: 0.6381 - val_loss: 1.1542 - val_accuracy: 0.6522\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.9183 - accuracy: 0.7429 - val_loss: 1.0764 - val_accuracy: 0.7174\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.8232 - accuracy: 0.7524 - val_loss: 1.0433 - val_accuracy: 0.7609\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6536 - accuracy: 0.7905 - val_loss: 1.0417 - val_accuracy: 0.7609\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5686 - accuracy: 0.8190 - val_loss: 1.0715 - val_accuracy: 0.7391\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4943 - accuracy: 0.8381 - val_loss: 1.0780 - val_accuracy: 0.8043\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4597 - accuracy: 0.8762 - val_loss: 1.1144 - val_accuracy: 0.8261\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2971 - accuracy: 0.9429 - val_loss: 1.1663 - val_accuracy: 0.8261\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3793 - accuracy: 0.8952 - val_loss: 1.2532 - val_accuracy: 0.8261\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2718 - accuracy: 0.9238 - val_loss: 1.3417 - val_accuracy: 0.8261\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2715 - accuracy: 0.9143 - val_loss: 1.3934 - val_accuracy: 0.8261\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2429 - accuracy: 0.9048 - val_loss: 1.4097 - val_accuracy: 0.8261\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2422 - accuracy: 0.9238 - val_loss: 1.3668 - val_accuracy: 0.8261\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2195 - accuracy: 0.9429 - val_loss: 1.4234 - val_accuracy: 0.8261\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1336 - accuracy: 0.9714 - val_loss: 1.5429 - val_accuracy: 0.8261\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1647 - accuracy: 0.9619 - val_loss: 1.6689 - val_accuracy: 0.8261\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1044 - accuracy: 0.9810 - val_loss: 1.8146 - val_accuracy: 0.7826\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1179 - accuracy: 0.9619 - val_loss: 1.9380 - val_accuracy: 0.7826\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0739 - accuracy: 0.9810 - val_loss: 1.9686 - val_accuracy: 0.7826\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1706 - accuracy: 0.9619 - val_loss: 1.8733 - val_accuracy: 0.8261\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0848 - accuracy: 0.9714 - val_loss: 1.9035 - val_accuracy: 0.8478\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0825 - accuracy: 0.9810 - val_loss: 1.9785 - val_accuracy: 0.8478\n",
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_167 (Dense)           (None, 1024)              50176     \n",
      "                                                                 \n",
      " dense_168 (Dense)           (None, 512)               524800    \n",
      "                                                                 \n",
      " dense_169 (Dense)           (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_46 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_170 (Dense)           (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_171 (Dense)           (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_47 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_172 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_173 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_174 (Dense)           (None, 6)                 102       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 750,166\n",
      "Trainable params: 750,166\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "batch_size = 512            \n",
    "epochs = 200            \n",
    "\n",
    "history = model.fit(X_train,trainLabels,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs = epochs,\n",
    "                    validation_split = 0.3,\n",
    "                    callbacks=[early_stopping]\n",
    "                     )\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s - loss: 1.3311 - accuracy: 0.8308 - 40ms/epoch - 40ms/step\n",
      "\n",
      "Test loss : 133.1131100654602 %\n",
      "Test accuracy : 83.07692408561707 %\n"
     ]
    }
   ],
   "source": [
    "evaluation = model.evaluate(X_test,  testLabels,batch_size=batch_size, verbose=2)\n",
    "print()\n",
    "print(\"Test loss :\",evaluation[0]*100,\"%\")\n",
    "print(\"Test accuracy :\",evaluation[1]*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 3ms/step\n",
      "[[9.97202277e-01 6.22632069e-05 8.33580707e-05 2.56797415e-03\n",
      "  2.17098586e-05 6.25120811e-05]\n",
      " [4.56975686e-04 2.78348406e-03 5.35360368e-06 9.72820163e-01\n",
      "  3.65909480e-04 2.35680044e-02]\n",
      " [1.34928224e-09 9.76076109e-10 2.18797344e-04 7.09482606e-07\n",
      "  9.99780357e-01 6.66765132e-08]\n",
      " [4.24177832e-10 7.14580617e-11 1.20837040e-05 1.74200554e-09\n",
      "  5.89292018e-11 9.99987960e-01]\n",
      " [1.19982706e-02 5.72980046e-01 2.56340355e-01 9.83008444e-02\n",
      "  3.66085432e-02 2.37719640e-02]\n",
      " [6.29366785e-02 3.05527627e-01 8.57379884e-02 1.18549973e-01\n",
      "  3.97937465e-03 4.23268288e-01]\n",
      " [1.86826856e-11 1.31304356e-10 2.76708815e-05 3.36826673e-07\n",
      "  9.99971986e-01 1.91087359e-08]\n",
      " [2.27965824e-08 9.99881387e-01 1.30252303e-07 1.18421180e-04\n",
      "  2.51687018e-13 9.86638860e-09]\n",
      " [9.98570800e-01 2.76286573e-05 4.40507501e-05 1.31452747e-03\n",
      "  6.80306221e-06 3.61779785e-05]\n",
      " [7.41658255e-08 5.19600292e-07 2.30882055e-04 4.53169108e-04\n",
      "  9.99307156e-01 8.20110654e-06]\n",
      " [1.54353530e-10 4.60778471e-10 1.49924672e-04 2.20793481e-07\n",
      "  9.99849677e-01 7.42246300e-08]\n",
      " [1.06468040e-04 1.13120619e-02 8.74245167e-01 2.32809084e-03\n",
      "  9.49740479e-06 1.11998633e-01]\n",
      " [9.99302387e-01 5.46808224e-06 1.64612502e-05 6.63189858e-04\n",
      "  4.83787335e-06 7.71985560e-06]\n",
      " [8.04168463e-01 1.40619436e-02 9.91297662e-02 4.78114150e-02\n",
      "  3.83635401e-03 3.09920013e-02]\n",
      " [1.51163840e-04 1.53025449e-03 4.74800436e-06 9.90224779e-01\n",
      "  1.14856358e-03 6.94055483e-03]\n",
      " [1.11557310e-02 7.87203252e-01 1.32453769e-01 5.43781333e-02\n",
      "  4.30560624e-03 1.05035082e-02]\n",
      " [1.08638786e-14 3.45279426e-12 2.75763124e-01 1.26344296e-10\n",
      "  7.24236846e-01 5.27120188e-12]\n",
      " [2.71212903e-05 4.91319042e-05 1.86238613e-05 3.20380903e-04\n",
      "  3.96401951e-08 9.99584734e-01]\n",
      " [4.07180914e-06 2.51221491e-06 2.43896866e-04 4.52848235e-06\n",
      "  1.76456769e-08 9.99744952e-01]\n",
      " [2.47246339e-06 6.26059948e-04 6.26611474e-09 9.98389482e-01\n",
      "  6.45679791e-07 9.81400022e-04]\n",
      " [3.60201170e-07 1.25524120e-05 4.47170496e-05 8.87423158e-02\n",
      "  9.11116719e-01 8.33007507e-05]\n",
      " [1.75648051e-06 6.86433559e-05 6.35796653e-07 9.88206208e-01\n",
      "  1.03036650e-02 1.41909625e-03]\n",
      " [2.95662949e-06 2.15077094e-07 1.01999767e-05 4.87805255e-06\n",
      "  2.14777298e-08 9.99981761e-01]\n",
      " [4.82855830e-05 1.13093647e-05 2.19038498e-04 1.78044778e-04\n",
      "  3.07754385e-06 9.99540210e-01]\n",
      " [1.40645961e-05 2.08838057e-04 1.55778906e-07 5.94572067e-01\n",
      "  2.06878767e-07 4.05204713e-01]\n",
      " [9.99624968e-01 2.56508429e-06 9.35966636e-06 3.57023266e-04\n",
      "  1.77025493e-06 4.23194160e-06]\n",
      " [2.70429183e-07 1.46193827e-07 1.64152226e-07 4.12762893e-05\n",
      "  1.51147683e-09 9.99958158e-01]\n",
      " [5.01232535e-05 1.99160283e-03 1.43801088e-07 9.87614989e-01\n",
      "  2.30424962e-06 1.03409104e-02]\n",
      " [6.33859116e-08 2.76759147e-06 9.96188700e-01 5.06916149e-06\n",
      "  3.80164664e-03 1.69812949e-06]\n",
      " [1.03057055e-05 1.31219125e-03 1.06943734e-08 9.89149272e-01\n",
      "  6.90114987e-08 9.52822622e-03]\n",
      " [1.53372341e-04 9.88992989e-01 4.35528258e-04 1.03284186e-02\n",
      "  6.50494712e-07 8.90894007e-05]\n",
      " [9.99110281e-01 6.76430000e-06 2.40476656e-05 8.38625536e-04\n",
      "  7.94602965e-06 1.22615493e-05]\n",
      " [5.58373358e-07 4.78978254e-05 9.96306777e-01 5.10420905e-05\n",
      "  2.59619719e-05 3.56779061e-03]\n",
      " [4.70978448e-05 3.28446040e-04 9.66153800e-01 5.77694387e-04\n",
      "  3.13072465e-03 2.97621991e-02]\n",
      " [8.53834022e-03 9.05928135e-01 1.07254628e-02 6.14347123e-02\n",
      "  2.30347694e-04 1.31430170e-02]\n",
      " [6.25581233e-05 4.53234170e-05 4.37636481e-04 5.45910261e-05\n",
      "  2.03283463e-07 9.99399662e-01]\n",
      " [9.99667048e-01 1.81635528e-06 7.27556471e-06 3.19383136e-04\n",
      "  1.64599032e-06 2.84508769e-06]\n",
      " [6.86437124e-05 9.65987425e-03 5.38819904e-07 9.71307039e-01\n",
      "  1.73220394e-06 1.89622119e-02]\n",
      " [3.55119118e-03 9.34534848e-01 6.57356810e-03 5.15422821e-02\n",
      "  1.06324514e-04 3.69183416e-03]\n",
      " [5.66204952e-04 6.87065651e-04 9.91145134e-06 9.61810172e-01\n",
      "  7.99954031e-03 2.89271679e-02]\n",
      " [9.77317929e-01 3.01174327e-06 1.23792459e-04 6.77152304e-03\n",
      "  1.56020727e-02 1.81596479e-04]\n",
      " [1.97173702e-14 7.51785570e-13 5.59396285e-04 5.81752924e-10\n",
      "  9.99440610e-01 5.30937967e-11]\n",
      " [9.20644104e-01 8.95538367e-03 2.90254620e-03 5.76529950e-02\n",
      "  6.67527609e-04 9.17745102e-03]\n",
      " [7.71839314e-06 1.10552809e-03 9.95002214e-09 9.94979680e-01\n",
      "  2.48013436e-07 3.90677713e-03]\n",
      " [8.79182025e-08 4.13826092e-05 9.01960971e-12 9.99692559e-01\n",
      "  2.06673123e-09 2.65980751e-04]\n",
      " [1.71473021e-05 4.80566923e-05 2.64657992e-05 2.67493771e-04\n",
      "  2.78491310e-08 9.99640822e-01]\n",
      " [1.08691384e-04 1.04002571e-02 1.88711215e-06 9.53833520e-01\n",
      "  5.17159697e-06 3.56505848e-02]\n",
      " [1.24844650e-04 5.50022305e-05 1.14553077e-04 5.01076458e-04\n",
      "  1.44241483e-06 9.99203146e-01]\n",
      " [6.98843721e-08 1.34870515e-06 4.96245712e-01 7.07057279e-06\n",
      "  5.03740370e-01 5.45693501e-06]\n",
      " [1.72889046e-02 8.43577743e-01 3.08367647e-02 8.57888684e-02\n",
      "  1.98846101e-03 2.05192361e-02]\n",
      " [3.85847205e-04 1.13952775e-02 9.67740834e-01 5.62717672e-03\n",
      "  5.20460261e-03 9.64611210e-03]\n",
      " [1.70515978e-06 2.28169288e-08 1.55448378e-03 3.46997081e-06\n",
      "  9.98422980e-01 1.74325523e-05]\n",
      " [1.88486649e-09 4.01341668e-11 5.59459785e-08 7.71893993e-10\n",
      "  5.69527227e-13 1.00000000e+00]\n",
      " [9.99778450e-01 7.84355564e-07 5.19503647e-06 2.12409941e-04\n",
      "  1.76120375e-06 1.39121539e-06]\n",
      " [1.08016402e-05 1.82538715e-05 9.63363800e-06 5.16688975e-04\n",
      "  6.37441460e-08 9.99444544e-01]\n",
      " [9.99466717e-01 3.66287281e-06 1.18140251e-05 5.09517733e-04\n",
      "  3.21749008e-06 5.13676559e-06]\n",
      " [5.10941561e-07 9.45651409e-05 5.63720667e-11 9.98667002e-01\n",
      "  2.95136626e-09 1.23796309e-03]\n",
      " [9.97551143e-01 4.35455877e-05 8.63155365e-05 2.24119169e-03\n",
      "  3.00558386e-05 4.77089852e-05]\n",
      " [9.99794304e-01 5.30692034e-07 6.55902159e-06 1.93688596e-04\n",
      "  3.47131549e-06 1.46555749e-06]\n",
      " [2.48275160e-06 3.18842870e-03 3.03568370e-09 9.93435621e-01\n",
      "  1.66916774e-08 3.37345875e-03]\n",
      " [6.22402740e-06 1.02578162e-03 5.02250493e-01 2.28089673e-04\n",
      "  1.37972989e-07 4.96489286e-01]\n",
      " [2.24494645e-09 7.40815009e-09 1.95690038e-04 4.85702003e-06\n",
      "  9.99798715e-01 6.88164050e-07]\n",
      " [3.18652837e-07 1.09394263e-08 3.76780168e-04 4.86294812e-06\n",
      "  9.99616742e-01 1.30743513e-06]\n",
      " [2.16837798e-05 6.08047878e-04 3.53758293e-03 2.00632756e-04\n",
      "  6.54763355e-09 9.95632052e-01]\n",
      " [1.85287519e-07 9.99824464e-01 6.91625473e-07 1.74586618e-04\n",
      "  2.97790612e-12 1.25652491e-07]]\n"
     ]
    }
   ],
   "source": [
    "y_pred=model.predict(X_test)\n",
    "print(y_pred)\n",
    "# print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 3ms/step\n",
      "[0 3 4 5 0 1 4 1 0 4 4 1 0 0 3 1 4 5 5 3 4 3 5 5 3 0 5 3 2 3 1 0 2 2 1 5 0\n",
      " 3 1 3 0 4 0 3 3 5 3 5 4 1 2 4 5 0 5 0 3 0 0 3 5 4 4 5 1]\n"
     ]
    }
   ],
   "source": [
    "# Prediction & confusion matrix - test data\n",
    "y_prob = model.predict(X_test)\n",
    "y_pred = np.argmax(y_prob, axis=1)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 3 4 2 1 5]\n"
     ]
    }
   ],
   "source": [
    "print(testtarget.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11  0  0  0  0  0]\n",
      " [ 1  6  0  0  1  0]\n",
      " [ 1  1  2  0  0  4]\n",
      " [ 0  0  0 12  0  0]\n",
      " [ 1  0  0  2 10  0]\n",
      " [ 0  2  2  0  0  9]]\n"
     ]
    }
   ],
   "source": [
    "table1 = confusion_matrix(testtarget,y_pred)\n",
    "print(table1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the f1_score that used y_test and y_pred in y\n",
    "y=f1_score(testtarget,y_pred,average='macro') \n",
    "\n",
    "# calculate the accuracy and store it in a\n",
    "a=accuracy_score(testtarget,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7279889391654097\n",
      "0.7692307692307693\n"
     ]
    }
   ],
   "source": [
    "print(y)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testtarget = testtarget +1 \n",
    "# y_pred = y_pred +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 3, 4, 2, 1, 5], dtype=int64)"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testtarget.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=table1)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
